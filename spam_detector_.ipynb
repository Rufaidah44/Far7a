{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "spam detector .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rufaidah44/Far7a/blob/master/spam_detector_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMnCCmnS1oXO",
        "colab_type": "text"
      },
      "source": [
        "# Deep learning for Text Classification\n",
        "\n",
        "In this notebook I'll be using the neural networks algorithm to create a model that can classify dataset Messages as spam or not spam based on the dataset that we'll give to the model. If you don't know what is the spammy message look like it usually contain words like 'win', 'cash', 'money', 'winner' ,'free'..etc and it designed to be notice and tempt you to open it.And sometimes it contains CAPTIAL WORDS and alot of exclamation marks!!!. Our mission here is to train a model to predict spammy messages for us!\n",
        "\n",
        "Identify spam messages is **a binary classification problem** as messages are classified as either 'Spam' or 'Not Spam' and nothing else. Also, this is **a supervised learning problem**, as we will be feeding a labelled dataset into the model, that it can learn from, to make future predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhNSF4p81oXP",
        "colab_type": "text"
      },
      "source": [
        "## Step 1.1: Understanding our dataset\n",
        "\n",
        "\n",
        "Import the dataset into a **pandas** dataframe using the `.read_csv()` method. You can access it using the filepath `\"spam.csv\"`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mluBFL-l1oXQ",
        "colab_type": "text"
      },
      "source": [
        "The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBwbEcej2T_T",
        "colab_type": "code",
        "outputId": "f8aee19b-0d4c-4321-f684-f89a499d43e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!git clone -l -s https://github.com/gdg-ml-team/DevFest19\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DevFest19'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 70 (delta 35), reused 15 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (70/70), done.\n",
            "[Errno 2] No such file or directory: 'cloned-repo'\n",
            "/content\n",
            "DevFest19  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAWaqDQz1oXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oth4pgnL1oXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "a9563eec-159c-4802-ea09-10758ca07949"
      },
      "source": [
        "df = pd.read_csv(\"/content/DevFest19/spam.csv\", encoding=\"iso-8859-1\")\n",
        "df.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1  ... Unnamed: 4\n",
              "0   ham  ...        NaN\n",
              "1   ham  ...        NaN\n",
              "2  spam  ...        NaN\n",
              "3   ham  ...        NaN\n",
              "4   ham  ...        NaN\n",
              "5  spam  ...        NaN\n",
              "6   ham  ...        NaN\n",
              "7   ham  ...        NaN\n",
              "8  spam  ...        NaN\n",
              "9  spam  ...        NaN\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOyd3Jcu1oXZ",
        "colab_type": "text"
      },
      "source": [
        "As we see above there are five columns and only two have values the first one called `v1` and the second called `v2`\n",
        "so first we have to get only the two columns that contain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3dnMEXB1oXa",
        "colab_type": "code",
        "outputId": "0daff451-12cb-435d-f6c6-6339cb38b48b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = df[[\"v1\",\"v2\"]]\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXAz1s9d1oXc",
        "colab_type": "text"
      },
      "source": [
        "Good now we have two columns v1 and v2 but there names are meaningless so let's rename them `label` and `message`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZT7sBx71oXd",
        "colab_type": "code",
        "outputId": "de18b799-3e96-4b2b-e9d1-c5268e1cbe8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.rename(columns={\"v1\":\"label\",\"v2\":\"message\"},inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr_jDlr_1oXg",
        "colab_type": "text"
      },
      "source": [
        "## Step 1.2: Data Preprocessing\n",
        "Now that we have a basic understanding of what our dataset looks like, lets convert our labels to binary variables(we make binary classification), 0 to represent 'ham'(not spam) and 1 to represent 'spam' for ease of computation.\n",
        "\n",
        "Our model would still be able to make predictions if we left our labels as strings but we could have issues later when calculating performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57qLecvk1oXh",
        "colab_type": "code",
        "outputId": "e0a8daa8-1c7a-43e0-c96b-3a92e09d8b7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df['label'] = df.label.map({\"ham\":0,\"spam\":1})\n",
        "df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANvfRwrF1oXm",
        "colab_type": "text"
      },
      "source": [
        "## Step 2.1: Bag of words\n",
        "\n",
        "What we have here in our dataset is a large collection of text data (5,572 rows of data). Most ML algorithms rely on **numerical data** to be fed into them as input, and **our dataset are usually text**.\n",
        "\n",
        "Here we'd like to introduce the **Bag of Words(BoW)** concept which is a term used to specify the problems that have a collection of text data that needs to be worked with. The basic idea of BoW is to take a piece of text and count the frequency of the words in that text. It is important to note that the BoW concept treats each word individually and the order in which the words occur does not matter.\n",
        "\n",
        "Using a process which we will go through now, we can convert a collection of documents to a matrix, with each document being a row and each word(token) being the column, and the corresponding (row,column) values being the frequency of occurrence of each word or token in that document.\n",
        "\n",
        "For example:\n",
        "\n",
        "Lets say we have 4 documents as follows:\n",
        "\n",
        "\n",
        "[\n",
        "\n",
        "'Hello, how are you!',\n",
        "\n",
        "'Win money, win from home.',\n",
        "\n",
        "'Call me now',\n",
        "\n",
        "'Hello, Call you tomorrow?'\n",
        "\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrLSpSGh1oXm",
        "colab_type": "code",
        "outputId": "46fb70b7-336a-4665-ab58-62b79b9ddb63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "documents = ['Hello, how are you!',\n",
        "                'Win money, win from home.',\n",
        "                'Call me now.',\n",
        "                'Hello, Call you tomorrow?']\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vector = CountVectorizer()\n",
        "count_vector.fit(documents) # Fit the documents and then return the matrix\n",
        "count_vector.get_feature_names() # here the only words that we have"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['are',\n",
              " 'call',\n",
              " 'from',\n",
              " 'hello',\n",
              " 'home',\n",
              " 'how',\n",
              " 'me',\n",
              " 'money',\n",
              " 'now',\n",
              " 'tomorrow',\n",
              " 'win',\n",
              " 'you']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBwBNsQ51oXp",
        "colab_type": "code",
        "outputId": "74152bec-b01b-49ab-b17b-3bf14b406a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "doc_array =count_vector.transform(documents) # here we transform the text to the Bag of Words\n",
        "doc_array.toarray()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFaQtIWX1oXr",
        "colab_type": "text"
      },
      "source": [
        "let's convert it to more understandable way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao9-67UT1oXs",
        "colab_type": "code",
        "outputId": "f74796f7-42df-4cb4-df48-a8b88ce85f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "frequency_matrix = pd.DataFrame(doc_array.toarray(), columns=count_vector.get_feature_names())\n",
        "frequency_matrix"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>are</th>\n",
              "      <th>call</th>\n",
              "      <th>from</th>\n",
              "      <th>hello</th>\n",
              "      <th>home</th>\n",
              "      <th>how</th>\n",
              "      <th>me</th>\n",
              "      <th>money</th>\n",
              "      <th>now</th>\n",
              "      <th>tomorrow</th>\n",
              "      <th>win</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   are  call  from  hello  home  how  me  money  now  tomorrow  win  you\n",
              "0    1     0     0      1     0    1   0      0    0         0    0    1\n",
              "1    0     0     1      0     1    0   0      1    0         0    2    0\n",
              "2    0     1     0      0     0    0   1      0    1         0    0    0\n",
              "3    0     1     0      1     0    0   0      0    0         1    0    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPHh-fnV1oXu",
        "colab_type": "text"
      },
      "source": [
        "Congratulations! You have successfully implemented a Bag of Words problem for a document dataset that we created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJgWdx5u1oXv",
        "colab_type": "text"
      },
      "source": [
        "## Step 3.1: Training and Testing sets\n",
        "\n",
        "Now that we have understood how to deal with the BOW problem we can get back to our dataset and split it to train and test to use it with our model.\n",
        "\n",
        "   **TODO:**  Split the dataset into a training and testing set by using the `train_test_split` method in sklearn. Split the data using the following variables:\n",
        "\n",
        "   * X_train is our training data for the 'message' column.\n",
        "   * y_train is our training data for the 'label' column\n",
        "   * X_test is our testing data for the 'message' column.\n",
        "   * y_test is our testing data for the 'label' column Print out the number of rows we have in each our training and testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLZy2r-C1oXw",
        "colab_type": "code",
        "outputId": "d0239539-88ec-4a3d-a82a-fd2ef929e1c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['message'], \n",
        "                                                    df['label'], \n",
        "                                                    random_state=1)\n",
        "\n",
        "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
        "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
        "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in the total set: 5572\n",
            "Number of rows in the training set: 4179\n",
            "Number of rows in the test set: 1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9jumUsy1oX1",
        "colab_type": "text"
      },
      "source": [
        "# Step 3.2: Applying Bag of Words processing to our dataset.\n",
        "\n",
        "our mission now is to apply BoW in our dataset as we did before using `CountVectorizer()`.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Fit our training data(X_train) into CountVectorizer() and return the matrix.\n",
        "* we have to transform our testing data(X_test) to return the matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hvchcnb1oX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the CountVectorizer method\n",
        "count_vector = CountVectorizer()\n",
        "\n",
        "# Fit the training data and then return the matrix\n",
        "training_data = count_vector.fit_transform(X_train) # Fit will make it as dictionry of words\n",
        "\n",
        "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
        "testing_data = count_vector.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EeJlSDg1oX3",
        "colab_type": "code",
        "outputId": "3a4b9de0-816f-406f-e7d3-00bb28a7b4b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"The shape of the BoW is {} rows(sentences) and {} columns(features)\".format(training_data.shape[0],training_data.shape[1]))\n",
        "\n",
        "# we have to pass the features into the neural network so let's get the number of features\n",
        "input_shape = training_data.shape[1] \n",
        "print(\"The input shape is the features number which is \",input_shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the BoW is 4179 rows(sentences) and 7496 columns(features)\n",
            "The input shape is the features number which is  7496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um8qA4E01oX6",
        "colab_type": "text"
      },
      "source": [
        "## Step4: Deep learning implementation using Keras\n",
        "We will be using Deep neural networks to solve this binary classification challnage.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W82psxhJ1oX7",
        "colab_type": "code",
        "outputId": "ecb3d004-6dca-40c8-a965-ef0c27fec6e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INpZy3a01oX9",
        "colab_type": "text"
      },
      "source": [
        "## Build The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXDNn6tk1oX-",
        "colab_type": "code",
        "outputId": "2f7881ec-6685-4da2-f7af-5f1a2d1fb462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"The training data shape = \",training_data.shape)\n",
        "input_shape = training_data.shape[1] # The columns are the number of features\n",
        "print(\"The number of features in our dataset = \",input_shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training data shape =  (4179, 7496)\n",
            "The number of features in our dataset =  7496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0tUFNTN1oYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build The structure of Model\n",
        "model = keras.Sequential() \n",
        "# here we define 20 nodes with input shape 7496 and activation function called relu\n",
        "model.add(keras.layers.Dense(20, input_shape=(input_shape,), activation='relu')) \n",
        "# then the output 1 node because we have binary classifiaction (spam/ notspam) and the activation function called sigmoid \n",
        "model.add(keras.layers.Dense(1, activation='sigmoid')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7miOx1ri1oYD",
        "colab_type": "code",
        "outputId": "549abc23-4170-44dc-8eee-604cf9aa8217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # define the loss and the optimizer\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 20)                149940    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 149,961\n",
            "Trainable params: 149,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6OIrpG71oYG",
        "colab_type": "text"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5rjfTrA1oYG",
        "colab_type": "code",
        "outputId": "7448384c-f907-4638-9a6f-3cdbb03a1a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# pass the training data, training_labels(Y_train), define the epochs, the validation data\n",
        "model.fit(training_data, y_train, epochs=10, \n",
        "          validation_data=(testing_data, y_test),\n",
        "          verbose=1) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4179 samples, validate on 1393 samples\n",
            "Epoch 1/10\n",
            "4179/4179 [==============================] - 1s 228us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0586 - val_acc: 0.9885\n",
            "Epoch 2/10\n",
            "4179/4179 [==============================] - 1s 208us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0590 - val_acc: 0.9885\n",
            "Epoch 3/10\n",
            "4179/4179 [==============================] - 1s 213us/step - loss: 9.7770e-04 - acc: 0.9998 - val_loss: 0.0596 - val_acc: 0.9885\n",
            "Epoch 4/10\n",
            "4179/4179 [==============================] - 1s 218us/step - loss: 9.0521e-04 - acc: 0.9998 - val_loss: 0.0606 - val_acc: 0.9885\n",
            "Epoch 5/10\n",
            "4179/4179 [==============================] - 1s 210us/step - loss: 8.4062e-04 - acc: 0.9998 - val_loss: 0.0613 - val_acc: 0.9885\n",
            "Epoch 6/10\n",
            "4179/4179 [==============================] - 1s 209us/step - loss: 7.8078e-04 - acc: 0.9998 - val_loss: 0.0618 - val_acc: 0.9885\n",
            "Epoch 7/10\n",
            "4179/4179 [==============================] - 1s 208us/step - loss: 7.2626e-04 - acc: 0.9998 - val_loss: 0.0624 - val_acc: 0.9885\n",
            "Epoch 8/10\n",
            "4179/4179 [==============================] - 1s 210us/step - loss: 6.7420e-04 - acc: 0.9998 - val_loss: 0.0633 - val_acc: 0.9885\n",
            "Epoch 9/10\n",
            "4179/4179 [==============================] - 1s 201us/step - loss: 6.2743e-04 - acc: 0.9998 - val_loss: 0.0639 - val_acc: 0.9885\n",
            "Epoch 10/10\n",
            "4179/4179 [==============================] - 1s 205us/step - loss: 5.8364e-04 - acc: 0.9998 - val_loss: 0.0649 - val_acc: 0.9878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba926b54a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15gStCUW1oYK",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6IjKc5-1oYL",
        "colab_type": "code",
        "outputId": "1c523c0a-0e63-448b-aa15-53d9e6aa0cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "training_loss, accuracy1 = model.evaluate(training_data, y_train)\n",
        "testing_loss, accuracy2 = model.evaluate(testing_data, y_test)\n",
        "print(\"The training loss = {:2f},  and the accuracy = {:2f}\".format(training_loss, accuracy1))\n",
        "print(\"The testing loss = {:2f},  and the accuracy = {:2f}\".format(testing_loss, accuracy2))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-d8246ab24cb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtesting_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The training loss = {:2f},  and the accuracy = {:2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The testing loss = {:2f},  and the accuracy = {:2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[1;32m    688\u001b[0m                                    \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA4au1xU1oYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkCSvnf91oYX",
        "colab_type": "text"
      },
      "source": [
        "## Save the model and the Bow\n",
        " We'll save the model in **h5** format which contains the model architecture and the weigths of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGH9hfnz1oYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"SpamDetector.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO58_Cj01oYf",
        "colab_type": "text"
      },
      "source": [
        "### To save the BoW we need to save the feature names to fit them again when we use the model\n",
        "\n",
        "We can use `pickle` module for that. This module have two methods,\n",
        "\n",
        "Pickling(dump): Convert Python objects into string representation.\n",
        "\n",
        "Unpickling(load): Retrieving original objects from stored string representstion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hONpv35u1oYf",
        "colab_type": "code",
        "outputId": "b5dce422-fea8-4a92-bf21-368035299856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(\"The length of the bow = \",len(count_vector.get_feature_names()))\n",
        "print(\"-\"*30)\n",
        "print(\"some samples of the data : \")\n",
        "count_vector.get_feature_names()[720:730]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the bow =  7496\n",
            "------------------------------\n",
            "some samples of the data : \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abj',\n",
              " 'able',\n",
              " 'abnormally',\n",
              " 'about',\n",
              " 'aboutas',\n",
              " 'abroad',\n",
              " 'absolutely',\n",
              " 'absolutly',\n",
              " 'abstract',\n",
              " 'abt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMY_B2491oYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"bow_featureNames.txt\", \"wb\") as fp:   #Pickling\n",
        "    pickle.dump(count_vector.get_feature_names(), fp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rgbgkE-1oYa",
        "colab_type": "text"
      },
      "source": [
        "## Load the model and using it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of37vi6E1oYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ7QM4tQ1oYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "71d79ae0-ca36-4bec-d329-b5d7a2ee7ff8"
      },
      "source": [
        "loaded_model = load_model(\"SpamDetector.h5\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjcyK0iT1oYi",
        "colab_type": "text"
      },
      "source": [
        "Let's save the feature names into file to use it for applying bow again without load The data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2si8X-t1oYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_bow(message):\n",
        "    with open(\"bow_featureNames.txt\", \"rb\") as fp:   # Unpickling\n",
        "        loaded_names = pickle.load(fp)\n",
        "        count_vector = CountVectorizer()\n",
        "        fit_bow = count_vector.fit(loaded_names)\n",
        "        return count_vector.transform(message)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMngL7mq1oYo",
        "colab_type": "text"
      },
      "source": [
        "## Build code to predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncde3b7q1oYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spam_detector(message):\n",
        "    msg = [] # list because the Bow doesn't accept string\n",
        "    msg.append(message)\n",
        "    bow = fit_bow(msg)\n",
        "    predicting = model.predict(bow)\n",
        "\n",
        "    if float(predicting)*100 > 0.5:\n",
        "        return \"Spam\"\n",
        "    else:\n",
        "        return \"Not Spam\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asRBfX-K1oYs",
        "colab_type": "code",
        "outputId": "efb722b2-8d81-45f7-b63c-0f44861ee8cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = \"free cash just sign in\"\n",
        "spam_detector(x)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Spam'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGxeqyWy1oYv",
        "colab_type": "code",
        "outputId": "28965f8a-ddce-45e2-a45c-4e7f3044d5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = \"Hey man How are you\"\n",
        "spam_detector(y)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Spam'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqhCgh-J1oYx",
        "colab_type": "text"
      },
      "source": [
        "##### Congratulations! You have successfully designed a model that can predict if an message is spam or not!\n",
        "##### Thanks for reach The eand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9JkPWs81oYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q2dyhEu1oY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPDQhMsP1oY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}